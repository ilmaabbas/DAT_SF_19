{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 19: Homework 3 Assignment - Clustering with K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this homework assignment, we will get practice with our first unsupervised learning technique, clustering. We will analyze wholesale purchases by 440 clients of a wholesale distributor. \n",
    "\n",
    "Please do all your analysis to answer the questions below in this Jupyter notebook. Show your work.\n",
    "\n",
    "**Please submit your completed notebook by 6:30PM on Wednesday, January 20.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "The [Wholesale Customers dataset](http://archive.ics.uci.edu/ml/datasets/Wholesale+customers) and a description of the data is available from the UCI ML Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Load the dataset. Check for missing values, perform any normalization that you think is necessary (remember that K-means uses the Euclidean Distance function).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Channel  Region  Fresh   Milk  Grocery  Frozen  Detergents_Paper  \\\n",
      "0          2       3  12669   9656     7561     214              2674   \n",
      "1          2       3   7057   9810     9568    1762              3293   \n",
      "2          2       3   6353   8808     7684    2405              3516   \n",
      "3          1       3  13265   1196     4221    6404               507   \n",
      "4          2       3  22615   5410     7198    3915              1777   \n",
      "5          2       3   9413   8259     5126     666              1795   \n",
      "6          2       3  12126   3199     6975     480              3140   \n",
      "7          2       3   7579   4956     9426    1669              3321   \n",
      "8          1       3   5963   3648     6192     425              1716   \n",
      "9          2       3   6006  11093    18881    1159              7425   \n",
      "10         2       3   3366   5403    12974    4400              5977   \n",
      "11         2       3  13146   1124     4523    1420               549   \n",
      "12         2       3  31714  12319    11757     287              3881   \n",
      "13         2       3  21217   6208    14982    3095              6707   \n",
      "14         2       3  24653   9465    12091     294              5058   \n",
      "15         1       3  10253   1114     3821     397               964   \n",
      "16         2       3   1020   8816    12121     134              4508   \n",
      "17         1       3   5876   6157     2933     839               370   \n",
      "18         2       3  18601   6327    10099    2205              2767   \n",
      "19         1       3   7780   2495     9464     669              2518   \n",
      "20         2       3  17546   4519     4602    1066              2259   \n",
      "21         1       3   5567    871     2010    3383               375   \n",
      "22         1       3  31276   1917     4469    9408              2381   \n",
      "23         2       3  26373  36423    22019    5154              4337   \n",
      "24         2       3  22647   9776    13792    2915              4482   \n",
      "25         2       3  16165   4230     7595     201              4003   \n",
      "26         1       3   9898    961     2861    3151               242   \n",
      "27         1       3  14276    803     3045     485               100   \n",
      "28         2       3   4113  20484    25957    1158              8604   \n",
      "29         1       3  43088   2100     2609    1200              1107   \n",
      "..       ...     ...    ...    ...      ...     ...               ...   \n",
      "410        1       3   6633   2096     4563    1389              1860   \n",
      "411        1       3   2126   3289     3281    1535               235   \n",
      "412        1       3     97   3605    12400      98              2970   \n",
      "413        1       3   4983   4859     6633   17866               912   \n",
      "414        1       3   5969   1990     3417    5679              1135   \n",
      "415        2       3   7842   6046     8552    1691              3540   \n",
      "416        2       3   4389  10940    10908     848              6728   \n",
      "417        1       3   5065   5499    11055     364              3485   \n",
      "418        2       3    660   8494    18622     133              6740   \n",
      "419        1       3   8861   3783     2223     633              1580   \n",
      "420        1       3   4456   5266    13227      25              6818   \n",
      "421        2       3  17063   4847     9053    1031              3415   \n",
      "422        1       3  26400   1377     4172     830               948   \n",
      "423        2       3  17565   3686     4657    1059              1803   \n",
      "424        2       3  16980   2884    12232     874              3213   \n",
      "425        1       3  11243   2408     2593   15348               108   \n",
      "426        1       3  13134   9347    14316    3141              5079   \n",
      "427        1       3  31012  16687     5429   15082               439   \n",
      "428        1       3   3047   5970     4910    2198               850   \n",
      "429        1       3   8607   1750     3580      47                84   \n",
      "430        1       3   3097   4230    16483     575               241   \n",
      "431        1       3   8533   5506     5160   13486              1377   \n",
      "432        1       3  21117   1162     4754     269              1328   \n",
      "433        1       3   1982   3218     1493    1541               356   \n",
      "434        1       3  16731   3922     7994     688              2371   \n",
      "435        1       3  29703  12051    16027   13135               182   \n",
      "436        1       3  39228   1431      764    4510                93   \n",
      "437        2       3  14531  15488    30243     437             14841   \n",
      "438        1       3  10290   1981     2232    1038               168   \n",
      "439        1       3   2787   1698     2510      65               477   \n",
      "\n",
      "     Delicassen  \n",
      "0          1338  \n",
      "1          1776  \n",
      "2          7844  \n",
      "3          1788  \n",
      "4          5185  \n",
      "5          1451  \n",
      "6           545  \n",
      "7          2566  \n",
      "8           750  \n",
      "9          2098  \n",
      "10         1744  \n",
      "11          497  \n",
      "12         2931  \n",
      "13          602  \n",
      "14         2168  \n",
      "15          412  \n",
      "16         1080  \n",
      "17         4478  \n",
      "18         3181  \n",
      "19          501  \n",
      "20         2124  \n",
      "21          569  \n",
      "22         4334  \n",
      "23        16523  \n",
      "24         5778  \n",
      "25           57  \n",
      "26          833  \n",
      "27          518  \n",
      "28         5206  \n",
      "29          823  \n",
      "..          ...  \n",
      "410        1892  \n",
      "411        4365  \n",
      "412          62  \n",
      "413        2435  \n",
      "414         290  \n",
      "415        1874  \n",
      "416         993  \n",
      "417        1063  \n",
      "418         776  \n",
      "419        1521  \n",
      "420        1393  \n",
      "421        1784  \n",
      "422        1218  \n",
      "423         668  \n",
      "424         249  \n",
      "425        1886  \n",
      "426        1894  \n",
      "427        1163  \n",
      "428         317  \n",
      "429        2501  \n",
      "430        2080  \n",
      "431        1498  \n",
      "432         395  \n",
      "433        1449  \n",
      "434         838  \n",
      "435        2204  \n",
      "436        2346  \n",
      "437        1867  \n",
      "438        2125  \n",
      "439          52  \n",
      "\n",
      "[440 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv as csv\n",
    "\n",
    "sale = pd.read_csv('Wholesale.csv', header=0)\n",
    "print(sale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1) Look at the dataset. There are both continuous and categorical variables. What are the categorical variables? From a business perspective, what do those categorical variables represent?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Categorical variables are Channel and Region. They represent the buckets/clusters in which the continuous variables (Fresh, Milk, Grocery, Frozen, Detergents_Paper, Delicassen) are measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2) What results might we expect from the k-means clustering if we were to run it on the dataset as-is? Explain your thinking in words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If we were to run the dataset as is, I would guess there would be just a few clusters, maybe 3. That is because even though the datapoints are  so spread out, one of the smallest values is '3', and largest '43088', the number of datapoints is so big (440) that they can be grouped in just a few clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Using ONLY the continuous features in the dataset, apply the K-means algorithm to find clusters in the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Fresh  Frozen\n",
      "0         3  12669     214\n",
      "1         3   7057    1762\n",
      "2         3   6353    2405\n",
      "3         3  13265    6404\n",
      "4         3  22615    3915\n",
      "5         3   9413     666\n",
      "6         3  12126     480\n",
      "7         3   7579    1669\n",
      "8         3   5963     425\n",
      "9         3   6006    1159\n",
      "10        3   3366    4400\n",
      "11        3  13146    1420\n",
      "12        3  31714     287\n",
      "13        3  21217    3095\n",
      "14        3  24653     294\n",
      "15        3  10253     397\n",
      "16        3   1020     134\n",
      "17        3   5876     839\n",
      "18        3  18601    2205\n",
      "19        3   7780     669\n",
      "20        3  17546    1066\n",
      "21        3   5567    3383\n",
      "22        3  31276    9408\n",
      "23        3  26373    5154\n",
      "24        3  22647    2915\n",
      "25        3  16165     201\n",
      "26        3   9898    3151\n",
      "27        3  14276     485\n",
      "28        3   4113    1158\n",
      "29        3  43088    1200\n",
      "..      ...    ...     ...\n",
      "410       3   6633    1389\n",
      "411       3   2126    1535\n",
      "412       3     97      98\n",
      "413       3   4983   17866\n",
      "414       3   5969    5679\n",
      "415       3   7842    1691\n",
      "416       3   4389     848\n",
      "417       3   5065     364\n",
      "418       3    660     133\n",
      "419       3   8861     633\n",
      "420       3   4456      25\n",
      "421       3  17063    1031\n",
      "422       3  26400     830\n",
      "423       3  17565    1059\n",
      "424       3  16980     874\n",
      "425       3  11243   15348\n",
      "426       3  13134    3141\n",
      "427       3  31012   15082\n",
      "428       3   3047    2198\n",
      "429       3   8607      47\n",
      "430       3   3097     575\n",
      "431       3   8533   13486\n",
      "432       3  21117     269\n",
      "433       3   1982    1541\n",
      "434       3  16731     688\n",
      "435       3  29703   13135\n",
      "436       3  39228    4510\n",
      "437       3  14531     437\n",
      "438       3  10290    1038\n",
      "439       3   2787      65\n",
      "\n",
      "[440 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from bokeh.plotting import figure,show,output_notebook\n",
    "\n",
    "X = sale[['Region', 'Fresh', 'Frozen']]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=3, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(3)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1) Plot the Silhouette Coefficient as a function of the number of clusters (remember that you set the number of clusters as an input to K-means).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.51194539e+00   5.31520137e+03   2.20515358e+03]\n",
      " [  2.57851240e+00   2.04273719e+04   3.86278512e+03]\n",
      " [  2.73076923e+00   4.81178846e+04   9.15934615e+03]]\n"
     ]
    }
   ],
   "source": [
    "centers = km.cluster_centers_\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = list()\n",
    "target = X['Region']\n",
    "color_mapping = {1:'red',2:'blue',3:'orange'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange', 'orange']\n"
     ]
    }
   ],
   "source": [
    "for value in target:\n",
    "    new_color = color_mapping[value]\n",
    "    colors.append(new_color)\n",
    "print(colors)\n",
    "\n",
    "cluster_1 = X['Frozen']\n",
    "cluster_2 = X['Fresh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = figure(title='Clusters in Whole Sales', tools='')\n",
    "p.circle(x=cluster_1, y=cluster_2, size=5, color=colors)\n",
    "p.circle(x=centers[:,0], y=centers[:,1], alpha=0.4, color='green', size=100)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manykm = KMeans(10)\n",
    "manykm.fit(X)\n",
    "manycenters = manykm.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = figure(title='Clusters in Whole Sales', tools='')\n",
    "q.circle(x=cluster_1, y=cluster_2, size=5, color=colors)\n",
    "q.circle(x=centers[:,0], y=centers[:,1], alpha=0.4, color='green', size=100)\n",
    "show(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553415664765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "labels = km.labels_\n",
    "label_euclidean_score = silhouette_score(X,labels,metric='euclidean')\n",
    "print(label_euclidean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.415412794987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/IlmaKhan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "manylabels = manykm.labels_\n",
    "manylabels_euclidean_score = silhouette_score(X,manylabels,metric='euclidean')\n",
    "print(manylabels_euclidean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2) What is the ideal value for k, the number of clusters? Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5 looks like a good number of clusters to have in this dataset because our silhouette score is 0.55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3) How does your answer for 3.2 compare with your thoughts from 2.2 above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Well I was wrong- we actually have 5 clusters instead of, my guess, 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit Questions\n",
    "**The following questions are strongly encouraged, but not required for this homework assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Read the scikit-learn user guide section about [clustering](http://scikit-learn.org/stable/modules/clustering.html). Pay particular attention to the section about [assumptions](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html#example-cluster-plot-kmeans-assumptions-py).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) PCA & PLOTTING:** <br> With six continuous features, plotting our clusters in two dimensions will be challenging. We can use [Principal Components Analysis](http://scikit-learn.org/stable/modules/decomposition.html#pca) and then plot only the \"top two\" dimensions. More technically, these are the dimensions that capture most of the variance in our data set. For this extra credit question, read about [PCA in the sklearn.decomposition module](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), apply it to the wholesale dataset, repeat the k-means clustering, and plot your results using only the top two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here, should you choose to attempt it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
